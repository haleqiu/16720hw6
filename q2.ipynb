{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b78209739e273da3a3bdbb15ea5cc74d",
     "grade": false,
     "grade_id": "cell-c4ab9a740c51dfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"img/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7898acafc88387d3f7ce40720bf71ef2",
     "grade": false,
     "grade_id": "cell-3c6401138ee3087d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 16720 (B)  Object Tracking in Videos - Assignment 6 - Q2\n",
    "    Instructor: Kris                          TAs: Wen-Hsuan (Lead), Zen, Yan, Rawal, Paritosh, Qichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc9f65ed0eacde8b833f81bd82b98d8d",
     "grade": false,
     "grade_id": "cell-951f7cf42448155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38804a257a8f737c4d975806d09367df",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Matthew-Bakers Inverse Compositional Alignment with Affine Matrix\n",
    "\n",
    "### Q2.1: Implementation (10 PT write-up, 20 PT implementation)\n",
    "Now we will implement the Matthew-Bakers tracker to alleviate the computational costs of the the Lucas-Kanade tracker, as it only calculates the Hessian and Jacobian once per each video. Write the function with the following function signature:\n",
    "\n",
    "```\n",
    "            M = InverseCompositionAffine(It, It1, rect)\n",
    "```\n",
    "that computes the optimal local motion represented by a $2x3$ affine transformation matrix $M$ from frame $I_t$ to frame $I_{t+1}$ that minimizes\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathcal{L}=\\sum_{\\mathbf{x}}[\\mathbf{T}(\\mathbf{x})-\\mathbf{I}(\\mathbf{W}(\\mathbf{x} ; \\mathbf{p}))]^{2}. \n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "The inputs are structured identically to Q1.2, but you should replace the forward alignment algorithm with the inverse compositional alignment algorithm. You may also find these materials useful: [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2002_3/baker_simon_2002_3.pdf) and [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2003_3/baker_simon_2003_3.pdf).\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Please include the results of the algorithm on all five videos we have provided along with your code. Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do they have those differences? At what point does the algorithm break down and why does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0447ca55b183d49aedc2487b700c00a",
     "grade": false,
     "grade_id": "cell-75539a0c38616db4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def InverseCompositionAffine(It, It1, rect, thresh=.025, maxIt=100):\n",
    "    '''\n",
    "    Q2.1: Matthew-Bakers Inverse Compositional Alignment with Affine MAtrix\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        M: Affine mtarix (2x3)\n",
    "    '''\n",
    "    return 0\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "        # Set thresholds (you probably want to play around with the values)\n",
    "    W = np.identity(3)\n",
    "    dp = np.ones(6)\n",
    "    p = np.array([1.,0.,0.,0.,1.,0.])\n",
    "    threshold = thresh\n",
    "    maxIters = maxIt\n",
    "    i = 0\n",
    "    x1, y1, x2, y2 = rect\n",
    "    \n",
    "    \n",
    "    height, width = It.shape\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    ## image gradient\n",
    "    gy, gx = np.gradient(It1)\n",
    "    \n",
    "    intep_y, intep_x = int(y2-y1), int(x2-x1)\n",
    "    # intep_y, intep_x = 2*(y2-y1), 2*(x2-x1)\n",
    "    \n",
    "    y = np.arange(0, height, 1)\n",
    "    x = np.arange(0, width, 1)\n",
    "    current_linespace_x = np.linspace(x1, x2, intep_x)\n",
    "    current_linespace_y = np.linspace(y1, y2, intep_y)\n",
    "    current_grid_y, current_grid_x = np.meshgrid(current_linespace_y, current_linespace_x)\n",
    "    \n",
    "    interpolator_gx = RectBivariateSpline(y, x, gx)\n",
    "    interpolator_gy = RectBivariateSpline(y, x, gy)\n",
    "    interpolator_Current = RectBivariateSpline(y, x, It)\n",
    "    interpolator_Next = RectBivariateSpline(y, x, It1)\n",
    "    \n",
    "    Template = interpolator_Current.ev(current_grid_y, current_grid_x)\n",
    "    Ix = interpolator_gx.ev(current_grid_y, current_grid_x)\n",
    "    Iy = interpolator_gy.ev(current_grid_y, current_grid_x)\n",
    "    \n",
    "    I = np.vstack((Ix.ravel(),Iy.ravel())).T #(N, 2)\n",
    "    \n",
    "    jac_W = [np.array([[x, y, 1, 0, 0, 0],[0, 0, 0, x, y, 1]]) \\\n",
    "             for y,x in zip(current_grid_y.ravel(), current_grid_x.ravel())]\n",
    "    jac_W = np.array(jac_W) #(N, 2, 6)\n",
    "    \n",
    "    A = np.einsum(\"nc, ncp -> np\", I, jac_W)\n",
    "    \n",
    "    while np.sum(np.square(dp)) > threshold:\n",
    "        \n",
    "        # warp the template\n",
    "        warp_grid_x =  current_grid_x * W[0,0] +  current_grid_y * W[0,1] + W[0,2]\n",
    "        warp_grid_y =  current_grid_x * W[1,0] +  current_grid_y * W[1,1] + W[1,2]\n",
    "        \n",
    "        warp_I = interpolator_Next.ev(warp_grid_y, warp_grid_x)\n",
    "        \n",
    "        err = (Template - warp_I).reshape(-1)\n",
    "        \n",
    "        dp,_,_,_ = np.linalg.lstsq(A,err,rcond=None)\n",
    "        dW = np.vstack((dp.reshape(2,3), [0, 0, 1]))\n",
    "        dW[0,0] +=1; dW[1,1] +=1;\n",
    "        #W = W @(dW)\n",
    "        p+=dp\n",
    "    \n",
    "    W = p.reshape(2,3)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa5f7cdd94a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# run algorithm and collect rects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInverseCompositionAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     corners = np.array([[rect[0], rect[1], 1], \n\u001b[1;32m     38\u001b[0m                         [rect[2], rect[3], 1]]).transpose()\n",
      "\u001b[0;32m<ipython-input-8-842a6de2ed92>\u001b[0m in \u001b[0;36mInverseCompositionAffine\u001b[0;34m(It, It1, rect, thresh, maxIt)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mwarp_grid_y\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcurrent_grid_x\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mcurrent_grid_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mwarp_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolator_Next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp_grid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarp_grid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTemplate\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwarp_I\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/scipy/interpolate/fitpack2.py\u001b[0m in \u001b[0;36mev\u001b[0;34m(self, xi, yi, dx, dy)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.14\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \"\"\"\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mintegral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mya\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/scipy/interpolate/fitpack2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, dx, dy, grid)\u001b[0m\n\u001b[1;32m    926\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error code returned by pardeu: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfitpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbispeu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error code returned by bispeu: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test your algorithm and visualize results!\n",
    "\n",
    "# Load data\n",
    "data_name = 'landing' # could choose from (car1, car2, landing, race, ballet)\n",
    "data = np.load('./data/%s.npy' % data_name)\n",
    "\n",
    "# obtain the initial rect with format (x1, y1, x2, y2)\n",
    "if data_name == 'car1':\n",
    "    initial = np.array([170, 130, 290, 250])\n",
    "elif data_name == 'car2':\n",
    "    initial = np.array([59, 116, 145, 151])\n",
    "elif data_name == 'landing':\n",
    "    initial = np.array([440, 80, 560, 140])\n",
    "elif data_name == 'race':\n",
    "    initial = np.array([170, 270, 300, 370])\n",
    "elif data_name == 'ballet':\n",
    "    initial = np.array([700, 210, 775, 300])\n",
    "else:\n",
    "    assert False, 'the data name must be one of (car1, car2, landing, race, ballet)'\n",
    "\n",
    "numFrames = data.shape[2]\n",
    "w = initial[2] - initial[0]\n",
    "h = initial[3] - initial[1]\n",
    "\n",
    "# loop over frames\n",
    "rects = []\n",
    "rects.append(initial)\n",
    "\n",
    "for i in range(numFrames-1):\n",
    "\n",
    "    It = data[:,:,i]\n",
    "    It1 = data[:,:,i+1]\n",
    "    rect = rects[i]\n",
    "\n",
    "    # run algorithm and collect rects\n",
    "    M = InverseCompositionAffine(It, It1, rect)\n",
    "    corners = np.array([[rect[0], rect[1], 1], \n",
    "                        [rect[2], rect[3], 1]]).transpose()\n",
    "    newRect = np.matmul(M, corners).transpose().reshape((4, ))\n",
    "    rects.append(newRect)\n",
    "\n",
    "    # Visualize\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.add_patch(patches.Rectangle((rect[0], rect[1]), rect[2]-rect[0]+1, rect[3]-rect[1]+1, linewidth=2, edgecolor='red', fill=False))\n",
    "    plt.imshow(It1, cmap='gray')\n",
    "    plt.show()\n",
    "    ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e51668c14367108d67297049924981",
     "grade": true,
     "grade_id": "q2_1",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For some transparency: we evaluate on multiple frames in a given video starting from the first frame.\n",
    "# We then compare against the reference implementation and calculate the sum of all differences.\n",
    "# You should not need to tune anything for the autograding. We pass in the same hyperparameters for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d90151aa6f37d11f3d3c4c61d5eff9",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.2: Comparing Your Algorithms (write-up only, 10 PT)\n",
    "Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do we have those differences?  At what point does the algorithm break down and why does this happen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
